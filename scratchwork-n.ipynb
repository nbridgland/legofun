{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loads all datafiles into dataframes of the same name.  Not sure the with open statements are necessary.\n",
    "filenames = ['colors.csv', 'inventories.csv', 'inventory_parts.csv', 'inventory_sets.csv', 'part_categories.csv', 'parts.csv', 'sets.csv', 'themes.csv']\n",
    "\n",
    "with open(filenames[0]) as datafile:\n",
    "    colors = pd.read_csv(datafile)\n",
    "with open(filenames[1]) as datafile:\n",
    "    inventories = pd.read_csv(datafile)\n",
    "with open(filenames[2]) as datafile:\n",
    "    inventory_parts = pd.read_csv(datafile)\n",
    "with open(filenames[3]) as datafile:\n",
    "    inventory_sets = pd.read_csv(datafile)\n",
    "with open(filenames[4]) as datafile:\n",
    "    part_categories = pd.read_csv(datafile)\n",
    "with open(filenames[5]) as datafile:\n",
    "    parts = pd.read_csv(datafile)\n",
    "with open(filenames[6]) as datafile:\n",
    "    sets = pd.read_csv(datafile)\n",
    "with open(filenames[7]) as datafile:\n",
    "    themes = pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add theme info to rows in sets dataframe\n",
    "sets = pd.merge(sets, themes, left_on = 'theme_id', right_on = 'id')\n",
    "sets = sets.drop('id', axis = 1) #extra column from merge\n",
    "sets = sets.set_index(['set_num']) #rename the index to the set id\n",
    "sets.columns = ['setname', 'year', 'theme_id', 'num_parts', 'theme_name', 'parent_id'] #slightly inefficient way to rename the name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventory_parts = pd.merge(inventory_parts, colors, left_on = 'color_id', right_on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventory_parts = inventory_parts.drop('id', axis = 1)\n",
    "inventory_parts.columns=['inventory_id', 'part_num', 'color_id', 'quantity', 'is_spare', 'color_name', 'rgb', 'is_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories = inventories.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt to add the number of parts of each color to the inventories dataframe.\n",
    "#This takes a very long time.\n",
    "inventoryids = inventory_parts['inventory_id'].unique() #Gets the unique list of inventory_parts inventory ids\n",
    "colornames = colors['name'].unique() #same for color ids\n",
    "#initialize color column to 0\n",
    "for name in colornames:\n",
    "    inventories[name]=0\n",
    "groupedinventory = inventory_parts.groupby('inventory_id') #Generates a collection of little dfs, one for each id\n",
    "for k in inventoryids:\n",
    "    colorgroups = groupedinventory.get_group(k).groupby('color_name') #groups each little df by color_name\n",
    "    #counts the number of parts of each color, and inserts it to the appropriate entry in inventory sets\n",
    "    for name in colornames:\n",
    "        try: \n",
    "            inventories.loc[k,name] = int(colorgroups.get_group(name)['quantity'].sum())\n",
    "        except KeyError:\n",
    "            pass #have the code ignore all KeyErrors and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could now be merged with the sets dataframe and it would be sufficient, but there's something really weird going on with this data that needs to be explored more:\n",
    "\n",
    "Run the 2nd and 3rd cells in this notebook again before running these, otherwise you'll get a bunch of keyerrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the entires in inventories have unique inventory ids - no inventory shows up in more than one set\n",
    "#some sets do have more than one inventory\n",
    "print(len(inventories))\n",
    "print(len(inventories['id'].unique())) #I set id to the index above, whoops.  Reload the data from the begining and uncomment\n",
    "print(len(inventories['set_num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_sets has inventories that are in more than one set, not very many over all\n",
    "print len(inventory_sets)\n",
    "print len(inventory_sets['set_num'].unique())\n",
    "print len(inventory_sets['inventory_id'].unique())\n",
    "print len(inventory_parts['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total number of sets is slightly larger than the number of unique sets showing up in the inventories df\n",
    "print(len(sets))\n",
    "print(len(inventories['set_num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There also appear to be inventories that have no entries in inventory_parts - no parts in those?\n",
    "print len(inventory_parts)\n",
    "print 'unique inventories in inventory_parts: ', len(inventory_parts['inventory_id'].unique())\n",
    "print 'unique inventories in inventories: ', len(inventories['id'].unique())\n",
    "print 'unique inventories in inventories_sets: ', len(inventory_sets['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of the parts and sets entries are in inventories:\n",
    "ip = set(inventory_parts['inventory_id'].unique())\n",
    "i_s = set(inventory_sets['inventory_id'].unique())\n",
    "i = set(inventories['id'].unique())\n",
    "print len(i.difference(ip)) #number of things in i that aren't in ip\n",
    "print len(inventories['id'].unique()) - len(inventory_parts['inventory_id'].unique())\n",
    "print len(i.difference(i_s))\n",
    "print len(inventories['id'].unique()) - len(inventory_sets['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prints out all the set information for all the inventories that don't entries in inventory_parts\n",
    "#A lot of it is swag, but some things list that they have parts!\n",
    "inventory_parts\n",
    "ip = set(inventory_parts['inventory_id'].unique())\n",
    "i = set(inventories['id'].unique())\n",
    "\n",
    "inventories_not_in_parts = i.difference(ip)\n",
    "#print inventories_not_in_parts\n",
    "\n",
    "for x in inventories_not_in_parts:\n",
    "    weird_inv = inventories[inventories['id'] == x]\n",
    "    print sets.loc[weird_inv.iloc[0]['set_num']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
