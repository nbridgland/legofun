{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loads all datafiles into dataframes of the same name.  Not sure the with open statements are necessary.\n",
    "filenames = ['colors.csv', 'inventories.csv', 'inventory_parts.csv', 'inventory_sets.csv', 'part_categories.csv', 'parts.csv', 'sets.csv', 'themes.csv']\n",
    "\n",
    "with open(filenames[0]) as datafile:\n",
    "    colors = pd.read_csv(datafile)\n",
    "with open(filenames[1]) as datafile:\n",
    "    inventories = pd.read_csv(datafile)\n",
    "with open(filenames[2]) as datafile:\n",
    "    inventory_parts = pd.read_csv(datafile)\n",
    "with open(filenames[3]) as datafile:\n",
    "    inventory_sets = pd.read_csv(datafile)\n",
    "with open(filenames[4]) as datafile:\n",
    "    part_categories = pd.read_csv(datafile)\n",
    "with open(filenames[5]) as datafile:\n",
    "    parts = pd.read_csv(datafile)\n",
    "with open(filenames[6]) as datafile:\n",
    "    sets = pd.read_csv(datafile)\n",
    "with open(filenames[7]) as datafile:\n",
    "    themes = pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add theme info to rows in sets dataframe\n",
    "sets = pd.merge(sets, themes, left_on = 'theme_id', right_on = 'id')\n",
    "sets = sets.drop('id', axis = 1) #extra column from merge\n",
    "#sets = sets.set_index(['set_num']) #rename the index to the set id, maybe not useful\n",
    "sets.columns = ['set_num', 'setname', 'year', 'theme_id', 'num_parts', 'theme_name', 'parent_id'] #slightly inefficient way to rename the name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventory_parts = pd.merge(inventory_parts, colors, left_on = 'color_id', right_on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventory_parts = inventory_parts.drop('id', axis = 1)\n",
    "inventory_parts.columns=['inventory_id', 'part_num', 'color_id', 'quantity', 'is_spare', 'color_name', 'rgb', 'is_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventories = inventories.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Attempt to add the number of parts of each color to the inventories dataframe.\n",
    "#This takes a very long time.\n",
    "inventoryids = inventory_parts['inventory_id'].unique() #Gets the unique list of inventory_parts inventory ids\n",
    "colornames = colors['name'].unique() #same for color ids\n",
    "#initialize color column to 0\n",
    "for name in colornames:\n",
    "    inventories[name]=0\n",
    "groupedinventory = inventory_parts.groupby('inventory_id') #Generates a collection of little dfs, one for each id\n",
    "for k in inventoryids:\n",
    "    dummy = groupedinventory.get_group(k)\n",
    "    colornames = dummy['color_name'].unique() #same for color ids\n",
    "    colorgroups = dummy.groupby('color_name') #groups each little df by color_name\n",
    "    #counts the number of parts of each color, and inserts it to the appropriate entry in inventory sets\n",
    "    for name in colornames:\n",
    "        try: \n",
    "            inventories.loc[k,name] = int(colorgroups.get_group(name)['quantity'].sum())\n",
    "        except KeyError:\n",
    "            pass #have the code ignore all KeyErrors and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullinfo = pd.merge(inventories, sets, left_on = 'set_num', right_on ='set_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove extra info\n",
    "forprediction = fullinfo.drop(['version', 'setname', 'year', 'theme_name', 'parent_id'], axis=1)\n",
    "forprediction = forprediction.set_index('set_num') #otherwise trees get mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 2,  0,  8, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm half-way through turning this into something reasonable.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Now choose a random subset of that for training/testing\n",
    "np.random.seed=4 #comment out for fun reruns, used later\n",
    "msk = np.random.rand(len(forprediction)) < 0.8\n",
    "forprediction_train = forprediction[msk]\n",
    "forprediction_test = forprediction[~msk]\n",
    "\n",
    "#Take away the answers\n",
    "y_train = forprediction_train['theme_id']\n",
    "y_test = forprediction_test['theme_id']\n",
    "x_train = forprediction_train.drop('theme_id', axis = 1)\n",
    "x_test = forprediction_test.drop('theme_id', axis = 1)\n",
    "\n",
    "\n",
    "#Make the tree\n",
    "dt = DecisionTreeClassifier(min_samples_split=100)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "#Add predictions to original stuff\n",
    "pred = list(dt.predict(x_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories.set_index('set_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0504084264832\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for k in range(451):\n",
    "    accuracy += matrix[k][k]\n",
    "print float(accuracy)/len(y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories.join(sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could now be merged with the sets dataframe and it would be sufficient, but there's something really weird going on with this data that needs to be explored more:\n",
    "\n",
    "Run the 2nd and 3rd cells in this notebook again before running these, otherwise you'll get a bunch of keyerrors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the entires in inventories have unique inventory ids - no inventory shows up in more than one set\n",
    "#some sets do have more than one inventory\n",
    "print(len(inventories))\n",
    "print(len(inventories['id'].unique())) #I set id to the index above, whoops.  Reload the data from the begining and uncomment\n",
    "print(len(inventories['set_num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inventory_sets has inventories that are in more than one set, not very many over all\n",
    "print len(inventory_sets)\n",
    "print len(inventory_sets['set_num'].unique())\n",
    "print len(inventory_sets['inventory_id'].unique())\n",
    "print len(inventory_parts['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the total number of sets is slightly larger than the number of unique sets showing up in the inventories df\n",
    "print(len(sets))\n",
    "print(len(inventories['set_num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There also appear to be inventories that have no entries in inventory_parts - no parts in those?\n",
    "print len(inventory_parts)\n",
    "print 'unique inventories in inventory_parts: ', len(inventory_parts['inventory_id'].unique())\n",
    "print 'unique inventories in inventories: ', len(inventories['id'].unique())\n",
    "print 'unique inventories in inventories_sets: ', len(inventory_sets['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the parts and sets entries are in inventories:\n",
    "ip = set(inventory_parts['inventory_id'].unique())\n",
    "i_s = set(inventory_sets['inventory_id'].unique())\n",
    "i = set(inventories['id'].unique())\n",
    "print len(i.difference(ip)) #number of things in i that aren't in ip\n",
    "print len(inventories['id'].unique()) - len(inventory_parts['inventory_id'].unique())\n",
    "print len(i.difference(i_s))\n",
    "print len(inventories['id'].unique()) - len(inventory_sets['inventory_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This prints out all the set information for all the inventories that don't entries in inventory_parts\n",
    "#A lot of it is swag, but some things list that they have parts!\n",
    "inventory_parts\n",
    "ip = set(inventory_parts['inventory_id'].unique())\n",
    "i = set(inventories['id'].unique())\n",
    "\n",
    "inventories_not_in_parts = i.difference(ip)\n",
    "#print inventories_not_in_parts\n",
    "\n",
    "for x in inventories_not_in_parts:\n",
    "    weird_inv = inventories[inventories['id'] == x]\n",
    "    print sets.loc[weird_inv.iloc[0]['set_num']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
